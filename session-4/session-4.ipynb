{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 4 : Supervised learning (3/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "\n",
    "Run the script `datasets.py` like you did in the last notebook to load the functions used to generate artificial datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset of 300 points with make_forge()\n",
    "# and split it into a 270 points training set and \n",
    "# 30 points test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the training points on a 2d figure. Points with\n",
    "# class 1 should have the color 'salmon' and points with\n",
    "# the class 0 should have the color 'lightblue'.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Print the test points on the same figure with color\n",
    "# 'orange' for class 1 and 'blue' for class 0.\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SVM model for classification with SVC class.\n",
    "# Use a linear kernel. Train it and evaluate its accuracy\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# How many support vectors have been found for each class ?\n",
    "# Print them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run plots.py\n",
    "figure = plt.figure()\n",
    "\n",
    "# Visualize the decision boundary of your SVM. How many \n",
    "# points are misclassified ? Is your dataset linearly \n",
    "# separable ? Do you think it would be possible to improve \n",
    "# the accuracy of the model ? Explain why.\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train 5 other SVM with a modified value for the penalty\n",
    "# and plot the decision boundary for each one.\n",
    "# Explain the effect of this parameter (what happens if we \n",
    "# increase/decrease it ?)\n",
    "# Do you think it can help to prevent underfitting or \n",
    "# overfitting ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real case dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the breast cancer dataset and train a linear SVC\n",
    "# model on this dataset. You can create several models and\n",
    "# adjust the value of the penalty parameter to find the\n",
    "# optimal one. Can you get a better accuracy than the KNN\n",
    "# model (it was 0.923?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The activation function $f$ of a neuron can be linear or non linear. The most used activation functions are :\n",
    "* sigmoid\n",
    "* tanh\n",
    "* ReLu (rectified linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the example for sigmoid, plot the representation of\n",
    "# tanh and ReLu on the same graph. ReLu is defined as:\n",
    "# ReLu(x) = max(0, x)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "x = np.linspace(-5, 5, 100)\n",
    "sigmoid_x = sigmoid(x)\n",
    "\n",
    "figure = plt.figure()\n",
    "plt.plot(x, sigmoid_x, label=\"sigmoid\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use a non linearly separable dataset that looks\n",
    "# like two moons.\n",
    "from sklearn.datasets import make_moons\n",
    "X, y = make_moons(n_samples=100, noise=0.25, random_state=3)\n",
    "\n",
    "plt.scatter(X[:,0], X[:,1], c=y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, using a linear SVM does not seem to be the best choice. Let's use neural networks to be able to classify this dataset. First, split the data into a training and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a neural network with all default parameters.\n",
    "# Compute its accuracy and print its decision boundary\n",
    "# Do you think the neural network is good ? Explain why.\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There exist different algorithms to train a neural\n",
    "# network. The default one is called 'adam'. Use the\n",
    "# documentation to know what are the other kind of\n",
    "# algorithm. Create other networks with each type of\n",
    "# algorithm. Which one is the best ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default, the neural network has only 1 hidden layer of\n",
    "# 100 neurons. Use the right parameter to create a network\n",
    "# of 2 hidden layers, each one having 10 neurons.\n",
    "\n",
    "# Create other networks with different parameters to see if\n",
    "# many small layers is better than 1 big layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also modify the activation function of the\n",
    "# neurons in your network. Create a network for each type\n",
    "# of activation. Which one is the best ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
