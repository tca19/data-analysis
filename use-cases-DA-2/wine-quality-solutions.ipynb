{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine quality analysis with decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file `wine_quality.csv` contains information about chemical properties of some wines. Let's see if what we learned so far can help us to predict if a wine will be good based on its properties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load, examine, clean, prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read and parse the wine_quality.csv file.\n",
    "\n",
    "# The file is in CSV format. The pandas library is well\n",
    "# suited to read and parse each field.\n",
    "import pandas\n",
    "data = pandas.read_csv(\"wine_quality.csv\")\n",
    "\n",
    "# We can take a look at the dataset to see what it contains.\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# How many rows and columns does the dataset have ?\n",
    "\n",
    "n_rows, n_cols = data.shape\n",
    "print(\"The dataset has {} rows and {} columns.\".format(\n",
    "    n_rows, n_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# List all chemical properties of this dataset.\n",
    "\n",
    "print(\"The chemical properties of each wine are:\")\n",
    "for col_name in data.columns:\n",
    "    print(\"  -\", col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# What kind of wines are present in this dataset ?\n",
    "\n",
    "# With the previous question, we can see that the column\n",
    "# `type` indicates what are the different kind of wines.\n",
    "print(\"The different kind of wines in this dataset are:\")\n",
    "for kind in data.type.unique():\n",
    "    print(\"  -\", kind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find the right method to get the average/minimum/maximum value\n",
    "# of each column (and only these 3 information per column)\n",
    "\n",
    "# The method describe() of the DataFrame object `data` gives\n",
    "# many information (including the average/minimum/maximum)\n",
    "# but also other information like min/max or 1st/3rd quartile.\n",
    "# We need to select only the interesting information (row).\n",
    "data.describe().loc[[\"mean\", \"min\", \"max\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Does this dataset have any missing information ?\n",
    "\n",
    "data.isna().head(20)\n",
    "# Yes, this dataset has some missing values. For example, we\n",
    "# can see a value \"True\" in the 17th row of the table below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# How many missing values ?\n",
    "\n",
    "# .sum() computes the sum for each column. It gives the\n",
    "# number of missing values for each column (it interprets\n",
    "# True as 1 and False as 0). We need a second .sum() to get\n",
    "# the number of missing values in the entire dataframe.\n",
    "print(\"There are {} missing values in the dataframe.\".\n",
    "     format(data.isna().sum().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Which column has the most missing values ?\n",
    "\n",
    "print(\"The column with the most missing values is '{}'.\".\n",
    "     format(data.isna().sum().idxmax()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove the rows which have at least 1 missing value.\n",
    "\n",
    "n_before = len(data)\n",
    "data = data.dropna(axis='index') # this axis drops the rows\n",
    "\n",
    "# How many rows have been removed ?\n",
    "\n",
    "n_after = len(data)\n",
    "print(\"{} rows have been removed because they contained at \"\n",
    "      \"least 1 missing value.\".format(n_before - n_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use an histogram to see see the repartition of\n",
    "# the wine quality.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "quality_histogram = data.quality.value_counts().sort_index()\n",
    "quality_histogram.plot(kind=\"bar\", colormap=\"summer\")\n",
    "plt.title(\"Distribution of wines quality\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's consider that a wine is good if its quality is\n",
    "# at least 7. Replace the values in the \"quality\" column\n",
    "# with \"good\" if quality >= 7 and with \"not good\" otherwise.\n",
    "\n",
    "# We use the function where() of the numpy library to \n",
    "# create a new column based on the values of another column.\n",
    "import numpy as np\n",
    "data.quality = np.where(data.quality >= 7, \"good\", \"not good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create the input data (i.e. the properties) and the\n",
    "# label (i.e. the quality of wine) and assign them\n",
    "# to 2 different variables X and y. Our machine learning\n",
    "# algorithm needs to have both input and output data.\n",
    "\n",
    "# We choose our label (the output of our model) to be the \n",
    "# quality of the wine (either \"good\" or \"not good\"). The\n",
    "# other columns are used as the input data.\n",
    "X = data.drop([\"quality\"], axis=1)\n",
    "y = data.quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Separate your data into a training and a test set\n",
    "# with 80% for the training set.\n",
    "\n",
    "# 80% for the training set means that the test set has\n",
    "# only 20% (0.2) of the data.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                     test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting wine quality with a decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Is this a classification or a regression problem ?\n",
    "# Import the appropriate version of DecisionTree, then\n",
    "# train it with your training data.\n",
    "\n",
    "# We need to predict either the label \"good\" or \"not good\".\n",
    "# This is a binary classification problem (only 2 possible\n",
    "# class). We import the classifier version of DecisionTree.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "wine_tree = DecisionTreeClassifier(random_state=0)\n",
    "wine_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Oops, it seems that there is a problem! Indeed, most\n",
    "# machine learning algorithms only work with numerical vectors.\n",
    "# And our current training data still have some string values\n",
    "# (like the type or the quality). We need to transform them before\n",
    "# training our model.\n",
    "\n",
    "# sklearn comes with tools to transform non-numerical values.\n",
    "# In our case, we are going to use a LabelEncoder. Look at the\n",
    "# documentation to learn what is does.\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#?LabelEncoder\n",
    "\n",
    "# now create two encoders: one for the `type` in X, the other\n",
    "# for the `quality` in y. Use the trained encoders to transform\n",
    "# X_train, X_test, y_train and y_test.\n",
    "\n",
    "encoder_type = LabelEncoder()\n",
    "encoder_quality = LabelEncoder()\n",
    "\n",
    "encoder_type.fit(X.type)\n",
    "encoder_quality.fit(y)\n",
    "\n",
    "X_train.type = encoder_type.transform(X_train.type)\n",
    "X_test.type = encoder_type.transform(X_test.type)\n",
    "y_train = encoder_quality.transform(y_train)\n",
    "y_test = encoder_quality.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now train again your Decision Tree.\n",
    "\n",
    "wine_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# What is the accuracy of your model (both on training\n",
    "# and test sets) ? Do you think we are underfitting ? Overfitting ?\n",
    "\n",
    "train_acc = wine_tree.score(X_train, y_train)\n",
    "test_acc = wine_tree.score(X_test, y_test)\n",
    "print(\"Train accuracy: {:.3f}\".format(train_acc))\n",
    "print(\"Test accuracy: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are overfitting because the accuracy on the training set is perfect while it is not on the test set. It seems like the tree has learned by heart to predict the wine quality on the train dataset, but it cannot generalize well on data it has never seen (the test set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Look at the documentation of your DecisionTree model\n",
    "# and try to tune the hyperparameters: create other models\n",
    "# with different values for max_depth, min_samples_split, max_features...\n",
    "# Train them and evaluate their accuracy. What is the best accuracy\n",
    "# you obtain?\n",
    "\n",
    "max_depth = 5\n",
    "wine_tree2 = DecisionTreeClassifier(max_depth=max_depth,\n",
    "                                    random_state=0)\n",
    "wine_tree2.fit(X_train, y_train)\n",
    "print(\"With max_depth=\", max_depth)\n",
    "train_acc = wine_tree2.score(X_train, y_train)\n",
    "test_acc = wine_tree2.score(X_test, y_test)\n",
    "print(\"Train accuracy: {:.3f}\".format(train_acc))\n",
    "print(\"Test accuracy: {:.3f}\".format(test_acc))\n",
    "print()\n",
    "\n",
    "max_depth = 15\n",
    "wine_tree3 = DecisionTreeClassifier(max_depth=max_depth,\n",
    "                                    random_state=0)\n",
    "wine_tree3.fit(X_train, y_train)\n",
    "print(\"With max_depth=\", max_depth)\n",
    "train_acc = wine_tree3.score(X_train, y_train)\n",
    "test_acc = wine_tree3.score(X_test, y_test)\n",
    "print(\"Train accuracy: {:.3f}\".format(train_acc))\n",
    "print(\"Test accuracy: {:.3f}\".format(test_acc))\n",
    "print()\n",
    "\n",
    "min_samples_split = 5\n",
    "wine_tree4 = DecisionTreeClassifier(min_samples_split=min_samples_split,\n",
    "                                    random_state=0)\n",
    "wine_tree4.fit(X_train, y_train)\n",
    "print(\"With min_samples_split=\", min_samples_split)\n",
    "train_acc = wine_tree4.score(X_train, y_train)\n",
    "test_acc = wine_tree4.score(X_test, y_test)\n",
    "print(\"Train accuracy: {:.3f}\".format(train_acc))\n",
    "print(\"Test accuracy: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use the feature_importances_ attribute of your best model. What are\n",
    "# the three most important features to evaluate the quality of a wine?\n",
    "\n",
    "# The feature_importances_ attribute is a numpy array where\n",
    "# each value indicates the importance of the respective\n",
    "# feature. But there is no mapping between a score and the\n",
    "# chemical property it represents. We first build a DataFrame\n",
    "# which contains both information.\n",
    "z = pandas.DataFrame(wine_tree.feature_importances_,\n",
    "                     index=X_train.columns,\n",
    "                     columns=[\"Importance\"])\n",
    "\n",
    "# We can now sort by decreasing importance and take the\n",
    "# first three features.\n",
    "z.sort_values(by=\"Importance\", ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three most important features to predict the quality of a wine are:\n",
    "* alcohol\n",
    "* sulphates\n",
    "* residual sugar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting wine quality with random forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw in the course (and in this example) that Decision Trees can easily overfit. To prevent this, we can use Random forests instead. Random forests are a collection of decision trees, where each decision tree is trained differently. The prediction of the RandomForest is then the average (or the most frequent) prediction of all the decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use a RandomForest composed of 20 decision trees and\n",
    "# train it on your data. Evaluate its accuracy. Do you see\n",
    "# an improvement ?\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train other random forest classifiers with different\n",
    "# hyperparameters (n_estimators, max_features). Can you beat\n",
    "# the best accuracy you obtained with a single decision tree ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
